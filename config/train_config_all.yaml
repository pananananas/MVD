# Experiment tracking
version: v1
note: "Training adapters on 4 GPUs full clean dataset"

# Model parameters
architecture: stabilityai/stable-diffusion-2-1
torch_dtype: float32
use_memory_efficient_attention: true
enable_gradient_checkpointing: true

# Conditioning parameters
img_ref_scale: 0.5
cam_modulation_strength: 1.0

# Training parameters
learning_rate: 0.00001
dataset_samples: 20000 # null for full dataset
epochs: 10

num_gpus: 4
batch_size: 6
gradient_accumulation_steps: 2

num_workers: 16
val_check_interval: 0.1 # Check every x epochs
max_grad_norm: 1.0
early_stopping_patience: 20
max_checkpoints: 10
sample_interval: 10
save_checkpoint_interval: 1 # Save every 1 hour
checkpoint_path: null # Path to checkpoint to resume from

# Dataset parameters
dataset: Objaverse
image_size:
  - 768
  - 768
max_views_per_object: 8

# Feature toggles
use_camera_conditioning: true
use_image_conditioning: true
train_denoising_unet: false

# Logging parameters
modulation_log_interval: 5

# Scheduler Configuration
scheduler_config:
  use_shifted_snr_scheduler: true
  shift_noise_mode: "interpolated" # "default" or "interpolated"
  shift_noise_scale: 6.0 # In MVAdapter this is the number of views used to shift the noise schedule by log(n)

# Loss Configuration
loss_config:
  use_snr_loss: true
  snr_gamma: 5.0
